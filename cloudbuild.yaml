steps:
  - name: "hashicorp/terraform:1.6"
    id: infra
    entrypoint: "/bin/sh"
    args:
      - "-e"
      - "-o"
      - "pipefail"
      - "-c"
      - |
        # export GOOGLE_APPLICATION_CREDENTIALS="../terraform/gcp-creds.json"
        terraform init
        terraform apply -auto-approve -lock=false
        echo PROJECT_ID=$(terraform output -raw project_id) > /workspace/.env
        echo REGION=$(terraform output -raw region) >> /workspace/.env
        echo DATA_BUCKET = $(terraform output -raw gcs_dataset_bucket) >> /workspace/.env
        echo BQ_DATASET=$(terraform output -raw dataset_name) >> /workspace/.env
        echo TRAIN_BQ_TABLE=$(terraform output -raw train_bq_table) >> /workspace/.env
        echo TEST_BQ_TABLE=$(terraform output -raw test_bq_table) >> /workspace/.env
        echo ENDPOINT=$(terraform output -raw vertex_endpoint) >> /workspace/.env
        echo SERVICE_ACCOUNT=$(terraform output -raw service_account) >> /workspace/.env
    dir: "terraform"

  - name: "python:3.10"
    id: preprocess-pipeline
    entrypoint: "bash"
    args:
      - "-c"
      - |
        export GOOGLE_APPLICATION_CREDENTIALS="../terraform/gcp-creds.json"
        pip install -r pipeline-req.txt
        python preprocess-pipeline.py
    dir: "scripts"

  - name: "python:3.10"
    id: training-pipeline
    entrypoint: "bash"
    args:
      - "-c"
      - |
        export GOOGLE_APPLICATION_CREDENTIALS="../terraform/gcp-creds.json"
        pip install -r pipeline-req.txt
        python pipeline.py
    dir: "scripts"

  - name: "python:3.10"
    id: prediction-pipeline
    entrypoint: "bash"
    args:
      - "-c"
      - |
        # export GOOGLE_APPLICATION_CREDENTIALS="../terraform/gcp-creds.json"
        pip install -r pipeline-req.txt
        python prediction-pipeline.py
    dir: "scripts"

logsBucket: ci-cd-logs-bucket

options:
  logging: GCS_ONLY
